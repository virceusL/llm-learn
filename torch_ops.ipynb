{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mdata\u001b[49m)\n\u001b[0;32m      4\u001b[0m torch\u001b[38;5;241m.\u001b[39mzeros(size)\n\u001b[0;32m      5\u001b[0m torch\u001b[38;5;241m.\u001b[39mones(size)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.tensor(data)\n",
    "torch.zeros(size)\n",
    "torch.ones(size)\n",
    "torch.arange(start, end, step)\n",
    "torch.linspace(start, end, steps)\n",
    "torch.rand(size)\n",
    "torch.randn(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.reshape(tensor, shape) # 改变形状\n",
    "torch.permute(tensor, dims) # 交换维度顺序\n",
    "torch.transpose(tensor, dim0, dim1) # 交换指定两个维度\n",
    "torch.squeeze(tensor, dim) # 移除指定维度, **仅移除大小=1的维度, dim=0不变\n",
    "torch.unsqueeze(tensor, dim) # 添加指定维度, eg. x(4,).unsqz(0) -> (1,4), unsqz(1) -> (4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat(tensors, dim) # 在指定维度上拼接, eg. x(2,3) cat((x,x),0) -> (4,3), cat((x,x),1) -> (2,6)\n",
    "torch.stack(tensors, dim) # 在指定维度上堆叠, eg. x(2,3) stack((x,x),0) -> (2*,2,3), stack((x,x),1) -> (2,2*,3)\n",
    "torch.split(tensor, split_sizes, dim) # =tensor.split(split_sizes, dim)\n",
    "torch.chunk(tensor, chunks, dim) # =tensor.chunk(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.dot(a, b) # must 1D [dim,]\n",
    "torch.mm(a, b) # torch.matmul(a, b), 都为2D时 =a @ b\n",
    "torch.bmm(a, b) # batch matrix multiply, 都为3D时 =a @ b\n",
    "# 高维张量时, 都默认在最后两个维度@ eg. Attention\n",
    "torch.t(a) # a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(tensor, dim)\n",
    "torch.mean(tensor, dim)\n",
    "torch.max(tensor, dim) # min\n",
    "torch.std(tensor, dim)\n",
    "torch.var(tensor, dim)\n",
    "torch.argmax(tensor, dim) # argmin\n",
    "\n",
    "torch.pow(tensor, exponent)\n",
    "torch.exp(tensor) # log\n",
    "torch.sin(tensor) # cos\n",
    "torch.clamp(tensor, min, max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor[index] # indexing\n",
    "tensor[: ,1:3, ...] # slicing\n",
    "torch.index_select(tensor, dim, index) # 对dim维的选择, index 1D, eg. [3,4],dim=0,index=[0,2] -> 提取出0维上的0和2 -> shape=[2,4]\n",
    "torch.gather(tensor, dim, index) # high-dim index, eg. Attention\n",
    "torch.masked_select(tensor, mask) # bool mask =x.ge(0.5), =torch.isnan(tensor), ..., return 1D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.broadcast_to(tensor, shape) # 广播到高维, eg. [3,] broadcast(3,3) -> shape=[3,3]\n",
    "tensor.expand(shape) # 从维度为1的扩张到高维, eg. expand(-1, 3) 保留[0]维, 扩展第[1]维到3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.to(device)\n",
    "tensor.cuda()\n",
    "tensor.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(\u001b[43moutputs\u001b[49m, inputs)\n\u001b[0;32m      2\u001b[0m tensor\u001b[38;5;241m.\u001b[39mrequires_grad_()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'outputs' is not defined"
     ]
    }
   ],
   "source": [
    "torch.autograd.grad(outputs, inputs)\n",
    "tensor.requires_grad_()\n",
    "tensor.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sort(tensor, dim)\n",
    "torch.argsort(tensor, dim)\n",
    "torch.nn.functional.normalize(tensor, p, dim)\n",
    "torch.sparse_coo_tensor(indices, values, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
